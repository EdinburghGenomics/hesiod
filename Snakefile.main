#!/bin/bash
# vim: ft=python

# Contents >>>
#   + Embedded BASH script to bootstrap the workflow
#   + Initialisation and configuration
#   + Helper functions
#   + The rules specific to this workflow
#   + More generic rules

# This workflow expects to be run in the output directory and see input files at ./rundata

"""true" ### Begin shell script part
set -u

source "`dirname $0`"/shell_helper_functions.sh

# The TOOLBOX setting gets passed down to jobs that run on SLURM. The PATH setting
# does not, as SLURM resets that env var.
export TOOLBOX="$(find_toolbox)"
export PATH="${PATH}:$(dirname "$0")"

snakerun_drmaa "$0" "$@"

"exit""" ### End of shell script part
#!/usr/bin/env snakemake

import yaml
from snakemake.utils import format
from glob import glob
import subprocess

TOOLBOX = 'env PATH="{}:$PATH"'.format(os.environ['TOOLBOX'])

for p in os.environ['PATH'].split(':'):
    if os.path.abspath(p) == os.path.dirname(os.path.abspath(workflow.snakefile)):
        break:
else:
    # The directory containing this file should be in the PATH
    os.environ['PATH'] += ':' + os.path.dirname(workflow.snakefile)

# If not supplied, just assume the usual symlink will work...
RUNDIR = config.get('rundata', 'rundata')

def scan_cells():
    """ Work out all the cells to process. Should be simple since the list is passed
        in config['cells'] but I do want to be able to process all by default.
        Then get a list of all the files per cell.
        TODO - can we avoid doing this if --allowed-rules is specified?
    """
    cells = [ '/'.join(fs.split('/')[-3:-1]) for fs in glob("{}/*/*/final_summary.txt".format(RUNDIR)) ]

    if 'cells' in config:
        cells = [ s for s in all_done if s in config['cells'].split('\t') ]
    else
        cells = all_done

    res = { c: dict() for c in cells }

    for c, d in res.items():
        for category in 'fastq_pass fast5_pass fastq_fail fast5_fail'.split():
            filetype = category.split('_')[0]
            d[category] = [ f[len(RUNDIR) + 1:]
                            for f in glob(format"{RUNDIR}/{c}/{category}/*.{filetype}") ]

    return res

SC = scan_cells()
if 'logging' in globals():
    # Make a dict that just shows the counts
    sc_counts = { c : { category: "{} files".format(len(filelist))
                        for category, filelist in d.items() }
                  for c, d in SC.items() }

    logging.info("SC = {!r}".format(sc_counts))

# Aggregate for all cells
ALL_FASTQ_PASS = [ format("{c}/{category}/{f}") for c, d in SC.items() for f in d['fastq_pass'] ]
ALL_FAST5_PASS = [ format("{c}/{category}/{f}") for c, d in SC.items() for f in d['fast5_pass'] ]
ALL_FASTQ_FAIL = [ format("{c}/{category}/{f}") for c, d in SC.items() for f in d['fastq_fail'] ]
ALL_FAST5_FAIL = [ format("{c}/{category}/{f}") for c, d in SC.items() for f in d['fast5_fail'] ]
ALL_FILES = [ format("{c}/{category}/{f}") for c, d in SC.items() for category, files in d.items() for f in files ]

# Main driver rule. Forces compression by requesting the .gz.md5 files
def one_cell_info:
    output: "{cell}.info.yml"
    input:
        all_md5 = [ f + '.gz.md5' for f in ALL_FILES ],
        blob_plots = "{}{}/{}.png" for c in SC,

