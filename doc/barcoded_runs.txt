Let's start sorting the barcoded runs.

eg. /lustre-gseg/promethion/prom_runs/2021/20210520_EGS1_16031BA/pipeline/

Pipeline fails at the point of running Snakemake as there are no files.

{'16031BApool01/20210520_1105_2-E1-H1_PAG23119_76e7e00f': {'fast5_fail': '<0 files>',
                                                           'fast5_pass': '<0 files>',
                                                           'fastq_fail': '<0 files>',
                                                           'fastq_pass': '<0 files>'}}

So the data structure needs to be re-jigged:

cell -> barcode -> 'fastX_pass' : [ list of files ]

For un-barcoded reads the barcode will be '.' cos we're just be using the subdirectory name.

OK, let's make myself a test run.

/lustre-gseg/home/tbooth2/test_promethion/runs/2021/20210520_EGS1_16031BA

I reduced it to 4 barcodes plus unassigned (2 are real and 2 not) and I pruned out a load of reads from this big boi.

Now just to test the logic that counts the reads - ok I added a whole bunch of tests to the Snakefile and the
util functions.

Now:

1) Get the files processed per-barcode.
2) Get some stats (counts per barcode - how best to do this? how do I count reads just now?)
3) Make the reports more better
4) Work out how I can maybe add in the sample names (hmmm)

Output file naming conventions - for the compressed fast5 files they go into cell/fast5_bcname_pass/
For the fastq the combined files are longid_bcname_pass.fastq.gz

OK I got the Snakefile to make a DAG and run. What's failing? parse_blob_table.py
Do I have unit tests for this thing? Why yes. good.

---

After getting the report made, it's not too bad.

Blob plots are broken links, and the headings need to say "for barcode01 passed reads" instead of "for all".
(fixed)

_counts in cell_info.yml are only for the first barcode, even though we have count files for all barcodes.
(working on this - want to aggregate per project then break out per cell)

We need a histo of reads per barcode. Can newer NanoPlot do this?? Nope. But I guess I can do a stacked bar plot.
Do the table first then.

After read counts table in the per-cell bit, add a table of "Reads per barcode" only if there are barcodes.
Headings are: barcode, all_passed, lambda-filtered passed, failed

---

After deployment, we have a problem. It looks like the DAG building is just too complex for a real run. I think it's because of
the blob plots, which involve splitting each barcode into 100 chunks, so for 20 barcodes that's 2000+ jobs. But it's not that
big, compared to all the FASTQ/FAST5 files to process. But hmmm, I may need to break the processing down into multiple steps.
This could be tricky. Maybe putting the .snakefile directory into shared memory would help? It's hacky, but I like hacks. We
couldn't do it with the whole directory since Snakemake uses it for shadow and script sharing, but maybe 'metadata' - it looks
like the sort of thing that might slow the system down. Matbe we can nix it??

For now let's just try having 20 chunks rather than 100.
