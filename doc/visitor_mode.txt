Proposal for ONT experiment naming.

The aim is to differentiate our internal flowcells from lab visitor flowcells and process them accordingly.

* For internal flowcells, we will continue to assign them to projects and samples based on the
  library/pool ID (eg. 23456XX0001) and make a Hesiod report and RT ticket.
* For visitor flowcells, we want to allow people to freely use their own sample/pool names.
  And their own preferred instrument settings in general.

At the moment, all experiments are regarded as internal and processed accordingly by the pipeline, regardless of the
name. Proposal is to use the experiment name to differentiate the types, with the rules as follows:

* Any experiment beginning with a number is regarded as internal and processed as now
* Any experiment beginning with v_xxxx is regarded as a visitor experiment, and xxxx should
  be the UUID of the visitor (eg. "v_marno" or "v_tbooth2_topups")
* Anything not matching either pattern will be regarded as a test run

Ultimately, this should make it really simple for me to automate it such that visitor data gets punted directly onto
our transfer server and the UUID receives a notification mail, with no intervention from us, and we don't have to try
and untangle situations like the other week where the pipeline started trying to process visitor data and got upset
and then stopped doing rsync.

Specific thoughts:

1. Why have the "v_" prefix at all?
   The idea is to make these experiments really obvious when listing the data directory, and also in future
   if we decide we want to make internal experiments that don't start with numbers (eg. K1234) we can do that more easily.
2. What if the user mis-types their UUID or uses a different naming scheme?
   I'll make it so the default behaviour can be overridden, so we can always correct that in some quick and reasonable way.
3. How soon can this be implemented?
   It's a fair bit of work to get to fully automatic delivery but there is no reason not to adopt the new naming
   scheme immediately.
4. What if the visitor is resequencing samples from an existing project, like with 14211AT?
   The use of the "v_uuid" naming scheme would still apply, if we were to do this again, but they could use "v_uuid_14211"
   to indicate that the samples relate to the old project (but Hesiod will not try to merge the samples with what we
   have as internal project data, even if the samples/pools have the same names).
5. What if the user does not have a UUID?
   I'm assuming every user will, but in case one does not they could use one of ours, or "edgenom1", and whoever
   gets the delivery e-mail with the transfer download token would just have to forward it.

Specific differentiation logic on run name:

if /v[_-]+([a-z0-9]+).*/i:
    type = "visitor"
    uuid = $1
elif /[0-9].*/:
    type = "internal"
else:
    type = "test"

I'll make a tiny script that saves this as pipeline/type.yaml. This will be regenerated if missing, but may be edited.
The pipeline will use it to work out how to process the expt. run_status.py will report the contents and I'll capture
this in driver.sh in the usual way.

Then in terms of implementation, the first step is to say that visitor and test runs get no further processing.
Then the pipeline probably wants to md5sum all files in the visitor runs. This can be a bit tricky as I don't want
to run all md5sums as one job (too long) but I also don't want to run as tiny separate jobs (too many jobs).
What can I do? Some files are small and some are big so bunching up 100 files seems a bit meh. But looking up
the size of all files requires too many stat() calls. So....

Maybe make a script that takes the list of files to be md5summed and makes:

md5sums_000.fofn
md5sums_001.fofn
md5sums_002.fofn
...

Or I could use a single YAML file and just have a list of lists. I could scramble the order of files to try and get a
mix of sizes in my blocks. If that fails I could add whatever checks on size or heuristics or whatever.

ANyyyway - then Snakemake makes the md5sums_000.txt [...] and then merges them all, with a rule like:

xargs md5sum -- < md5sums_000.fofn

I'd have to put the md5sums somewhere. Probably we can just work in the pipeline/ directory but I don't want to
run Snakemake in there, so maybe we do need an output directory for these runs. Yeah, I think I do. Then the
delivery involves moving the cell directory to the transfer server and copying the final md5sums file to a
suitable location. Probably best to make it obvious, so put it at the top level of the delivery folder.

We can keep the output dir for now and not worry about cleanup - there's not much in there.

Then trigger my delivery logic to make a token, and send an e-mail. But I don't think this belongs in Hesiod,
so I think we may end up calling some qc_tools_python logic here. But this is fine. All fine. Then we can keep
the e-mail template in with disseminate_results.py with the other stuff. Do we ask for an acknowledgement in the
same way? TODO - check that.

---

## Manual delivery of these user runs

On 2/10/23 - we already have some runs done using this naming scheme, specifically:

20230926_EGS2_v_mmarr3_EXP_SONT001a
20230926_EGS2_v_mmarr3_EXP_SONT001b
20230926_EGS2_v_mmarr3_EXP_SONT001c
20230926_EGS2_v_mmarr3_EXP_SONT001d
20230928_EGS2_v_mmarr3_EXP_SONT001e
20230928_MIN2_v_yzhang35_run1

I didn't expect Melissa to make multiple experiments, but there's no reason why she shouldn't do.
A few thoughts here:

1) A user could potentially make any number of experiments, and add new flowcells to those experiments,
either with new samples or with re-runs of existing sample names.

I delivered 20230928_MIN2_v_yzhang35_run1 as:

/lustre-gseg/transfer/nanopore_v_yzhang35/20230928_MIN2_v_yzhang35_run1/P1-3/20230928_1133_MN32284_APP107_ffde8584/
/lustre-gseg/transfer/nanopore_v_yzhang35/20230928_MIN2_v_yzhang35_run1/P1-3_md5sums.txt

But this is not robust in general as he could run a second flowcell on this sample, and then there would be a filename
clash with the md5sums. I could do this, using the unique(ish) ID part of the run element ID:

/lustre-gseg/transfer/nanopore_v_yzhang35/20230928_MIN2_v_yzhang35_run1/P1-3_ffde8584_md5sums.txt (1)

Or:

/lustre-gseg/transfer/nanopore_v_yzhang35/20230928_MIN2_v_yzhang35_run1_P1-3_ffde8584_md5sums.txt (2)

Or:

/lustre-gseg/transfer/nanopore_v_yzhang35/20230928_1133_MN32284_APP107_ffde8584_md5sums.txt (3)
/lustre-gseg/transfer/nanopore_v_yzhang35/20230928_MIN2_v_yzhang35_run1/20230928_1133_MN32284_APP107_ffde8584_md5sums.txt (4)

I think probably 3 is the way to go. On the minus side it leads to having long path names in the md5sums file, and it's
not immediately obvious which md5sums relate to which subdirectrory, but on the plus side it makes the md5sums file
prominent and avoids concocting a new file name as we just use the cell directory name. And it also makes it obvious that
this is the checksum file for one cell.

I'll go with this for now. So, to deliver the "mmarr3" experiments we do this:

1) $ mkdir /lustre-gseg/promethion/visitor_runs_delivery/20230926_EGS2_v_mmarr3 && cd <ditto>

We need a temporary directory to make the md5sums. This could be anywhere since we're only generating
one small file per experiment.

2) $ source ~pipeline/hesiod/current/_hesiod_venv/bin/activate

We need a specific version of Snakemake and this is the easiest way to get it.

3) $ ~pipeline/hesiod/current/Snakefile.checksummer --config input_dir="/lustre-gseg/promethion/prom_runs/2023/./20230926_EGS2_v_mmarr3_EXP_SONT001a/lamb9/20230926_1134_3B_PAO09471_f1c1bf28" op_index=-1

This depends on my having deployed an updated version of the pipeline. If "Snakefile.checksummer" doesn't exist it means I
didn't do this and you need to grab a copy from GIT.

4) Repeat (3) for all cells that need processing

You should be able to do this in the same directory as Snakemake has granular locking.

5) Now move the cells to the /lustre-gseg/transfer area. However, we want to leave the empty directories behind, so don't move the
whole experiment.

$ mkdir -p /lustre-gseg/transfer/nanopore_v_<uuid>/<expid>/<libid>
$ mv /lustre-gseg/promethion/prom_runs/2023/./20230926_EGS2_v_mmarr3_EXP_SONT001a/lamb9/20230926_1134_3B_PAO09471_f1c1bf28 /lustre-gseg/transfer/nanopore_v_mmarr3/20230926_EGS2_v_mmarr3_EXP_SONT001a/lamb9/

Note this involves use of 'sudo' just now, as the runs are owned by the pipeline account.
And the md5sums:

$ mv /lustre-gseg/promethion/visitor_runs_delivery/20230926_EGS2_v_mmarr3/*_md5sums.txt /lustre-gseg/transfer/nanopore_v_mmarr3/

6) And finally, generate a token for this download.

$ disseminate_results.py -p nanopore_v_mmarr3 --new_token

And check the URL looks OK:

https://transfer.genomics.ed.ac.uk/<token>

It's also a good idea to tell the user the size of the download - you can exclude .pod5 and .fast5 files:

$ du -csh --exclude='*.'{pod5,fast5} */*/

## Practical implementation - timing

Is it ok for users to get an e-mail for every cell they run? I guess so.
If they make multiple experiments then it seems inevitable, as the pipeline triggers experiments separately.
If they add multiple cells to one experiment, we may get them in batches depending on the sync cycle.

I guess I could add an arbitrary delay, say for example don't process a visitor experiment until everything
is at least an hour old. But this seems a bit silly. Also it's something I can add on later, rather than
an essential feature. For now let's say:

We'll continue to process experiments individually
But if there are multiple cells ready at one time we'll deliver all the cells at once (as per the current
driver mechanism).

I need a test case for this, Fortunately, easy to make. I'll concoct a visitor run for 'tbooth2' with
three cells, two of which are ready to deliver.

---

Question - what level of reporting should we have for visitor runs? I think we should have the same level
of chatter as regular runs, as in we get a ticket and then see a message if the run is delivered but
also an error if auto-delivery fails. But maybe this doesn't need to go to EVERYONE in the lab. Easiest
way is to have RT notifications go to a different queue for visitor runs and control notifications at
the RT level. So let's code that thing.
